# Asana Data Simulation Generator

A high-fidelity, scalable generator for creating realistic seed data for an Asana-like Reinforcement Learning (RL) environment.

## ğŸš€ Overview

This project simulates the data ecosystem of a mid-sized B2B SaaS company, **"TechFlow Solutions"**. It procedurally generates a complete Organization graphâ€”including Users, Teams, Projects, Tasks, Comments, and Custom Fieldsâ€”specifically designed to train and evaluate AI agents on complex project management workflows.

**Key Features:**
*   **High Scalability**: capable of generating 10,000+ entities efficiently.
*   **Hybrid Intelligence**: Uses a combination of **Llama 3 (via Groq)** and statistical heuristics to create data that looks and feels real.
*   **Relational Integrity**: Strictly enforces business logic (e.g., users are only assigned to projects within their teams).
*   **Temporal Realism**: Simulates a 6-month history with realistic work patterns (weekday clusters, creating vs. completion lag).

---

## ğŸ§  Methodology

### Data Generation Strategy
The system uses a **tiered approach** to balance quality and performance:

1.  **Tier 1: Statistical Backbone (Heuristics)**
    *   Used for: Dates, Statuses, Relationships.
    *   Logic: Weighted randoms based on real-world benchmarks (e.g., 85% of tasks due on weekdays, 15% unassigned backlog rate).

2.  **Tier 2: Semantic Layer (Templates)**
    *   Used for: Project names, standard tasks.
    *   Logic: Domain-specific templates derived from GitHub issues (e.g., `[Backend] Refactor API`).

3.  **Tier 3: Creative Layer (LLM/Groq)**
    *   Used for: Unique task descriptions, specific comments.
    *   Logic: "Few-shot" prompting to generate context-aware content (e.g., "Fix race condition in Auth service").

### Database Schema
The data is modeled in **SQLite** with strict foreign keys to ensure data validity. Key design patterns include:
*   **EAV (Entity-Attribute-Value)**: For flexible Custom Fields on tasks.
*   **Self-Referencing Tasks**: For infinite subtask hierarchy.
*   **Many-to-Many Memberships**: For Users belonging to multiple Teams.

---

## ğŸ›  Project Structure

```bash
â”œâ”€â”€ README.md                    # You are here
â”œâ”€â”€ requirements.txt             # Dependencies (Faker, Groq, etc.)
â”œâ”€â”€ schema.sql                   # Complete SQLite DDL (13 tables)
â”œâ”€â”€ .env.example                 # Config template
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                  # ğŸš€ Entry Point / Orchestrator
â”‚   â”œâ”€â”€ scrapers/                # Modules for external data
â”‚   â”œâ”€â”€ generators/              # ğŸ­ Logic for generating entities
â”‚   â”‚   â”œâ”€â”€ users.py             # Users & Teams
â”‚   â”‚   â”œâ”€â”€ projects.py          # Projects & Sections
â”‚   â”‚   â”œâ”€â”€ tasks.py             # Tasks & Subtasks (LLM-integrated)
â”‚   â”‚   â”œâ”€â”€ comments.py          # Activity Feed
â”‚   â”‚   â”œâ”€â”€ custom_fields.py     # EAV Pattern implementation
â”‚   â”‚   â””â”€â”€ tags.py              # Metadata
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ db.py                # Database helpers
â”‚   â”‚   â””â”€â”€ llm_helper.py        # Groq API wrapper with fallbacks
â”‚   â””â”€â”€ models/                  # Data models
â”œâ”€â”€ prompts/                     # LLM System Prompts
â””â”€â”€ output/
    â””â”€â”€ asana_simulation.sqlite  # ğŸ’¾ Final Database Artifact
```

---

## âš¡ Quick Start

### 1. Prerequisities
*   (Optional) A free **Groq API Key** for high-quality text generation.

### 2. Installation

```bash
# Clone the repository (if applicable)
# git clone ...

# Install dependencies
pip install -r requirements.txt
```

### 3. Configuration

Create a `.env` file to control the scale of the simulation:

```ini
# .env
DB_PATH=output/asana_simulation.sqlite

# Scale configuration
SEED_COUNT_USERS=50
SEED_COUNT_PROJECTS=20
SEED_COUNT_TASKS_PER_PROJECT=15

# (Optional) For LLM-powered text generation
# GROQ_API_KEY=gsk_...
```

### 4. Run the Generator

```bash
python -m src.main
```

You will see the generation progress in the terminal. The final result will be saved to `output/asana_simulation.sqlite`.

---

## ğŸ” Verification

To inspect the generated data, you can use any SQLite viewer or run the python checker (if provided):

```python
import sqlite3
# Example check
conn = sqlite3.connect("output/asana_simulation.sqlite")
print(conn.execute("SELECT COUNT(*) FROM tasks").fetchone()[0])
```

